# æ”¹åŠ¨
## ä¸€.æ±‰åŒ–
1.å°†æç¤ºè¯é€šè¿‡aiè¾…åŠ©æ±‰åŒ–ã€‚æ–¹ä¾¿è°ƒæ•´
2.è¾“å‡ºçš„logå’Œaiè¿”å›çš„å†…å®¹ä¹Ÿå˜æˆä¸­æ–‡ã€‚
>å°†ç¿»è¯‘æŒ‡ä»¤é‡Œçš„ç›®æ ‡è¯­è¨€æ”¹ä¸ºæ±‰è¯­(ctrl+f æŸ¥æ‰¾"en"æˆ–"è‹±è¯­'')
>æç¤ºè¯æ±‰åŒ–åä½¿å¾—aiä¹Ÿè¿”å›ç›¸åŒè¯­è¨€

## äºŒ.é‡è¿
æ„å¤–ä¸­æ–­åï¼Œå†æ¬¡å¯åŠ¨æ—¶å¯é€šè¿‡è¯»å–è®°å½•æ–‡ä»¶ï¼Œç»§ç»­ä¹‹å‰çš„è¿›åº¦ã€‚
>1å¤§çº²
>2ç« èŠ‚ç»†çº²
>3ç« èŠ‚
>4æ¸…æ´—ç« èŠ‚
>5æ€»ç»“
```
{
    "step": 1,
    "done_chapter_outlines": 0,
    "done_chapters": 0,
    "chapter_num": 6
}
```

Logs é‡Œé¢çš„æ–‡ä»¶å³ä¸ºè®°å½•æ–‡ä»¶ã€‚
record.jsoné‡Œé¢è®°å½•äº†å·²ç»å®Œæˆçš„ç« èŠ‚ç»†çº²å’Œç« èŠ‚æ•°ã€‚
step   è¿›è¡Œåˆ°å“ªä¸€æ­¥
chapter_num æ€»ç« èŠ‚æ•°
## ä¸‰.æ¨¡å‹çš„æ”¹åŠ¨
ç”µè„‘æ’‘ä¸èµ·åŸé¡¹ç›®çš„llama3:70bã€‚ç„¶åæœ¬äººåˆæ‡’å¾—å»é…å…¶ä»–çš„æ¨¡å‹ã€‚ç›´æ¥å…¨éƒ¨æ”¹ç”¨äº†ollamaçš„qwen2.5ã€‚
ä½†é€šè¿‡modelfileè°ƒæ•´äº†ä¸€ä¸‹ã€‚(æœ‰ä¸ªå°æ¯›ç—…,ç”¨vscodeçš„ctrl+/ æ³¨é‡Šé”®å‡ºæ¥çš„æ³¨é‡Šç¬¦";"æ— æ•ˆï¼Œéœ€è¦æ‰‹åŠ¨æ•²#)
```
#modelfile

#rwkv6æ¨¡å‹ä¸èƒ½ä½¿ç”¨   Error: llama runner process has terminated: GGML_ASSERT(inp != nullptr && "missing result_norm/result_embd tensor") failed
FROM qwen2.5:latest

# è®¾ç½®æ¸©åº¦ä¸º 1 [è¶Šé«˜è¶Šæœ‰åˆ›é€ åŠ›ï¼Œè¶Šä½è¶Šè¿è´¯]
PARAMETER temperature 1
# è®¾ç½®ä¸Šä¸‹æ–‡çª—å£å¤§å°ä¸º 4096ï¼Œè¿™æ§åˆ¶äº† LLM å¯ä»¥ç”¨æ¥ç”Ÿæˆä¸‹ä¸€ä¸ªæ ‡è®°çš„æ ‡è®°æ•°é‡
PARAMETER num_ctx 4096

# è®¾ç½®ä¸€ä¸ªè‡ªå®šä¹‰çš„ç³»ç»Ÿæ¶ˆæ¯æ¥æŒ‡å®šå°è¯´ä½œå®¶çš„è¡Œä¸º
#ä½¿ç”¨ä»‹ç»
#   ollama create example -f modelfile
#   ollama run example


#SYSTEM æ ¹æ®è¾“å‡ºçš„ç½‘ç»œå°è¯´æƒ…èŠ‚,ç”Ÿæˆç¬¦åˆå°è¯´æƒ…èŠ‚çš„äººç‰©å¡ç‰‡,äººç‰©å¡ç‰‡è®°å½•ç€ä¸åŒè§’è‰²çš„æ€§æ ¼,å¤–è²Œå’Œç»å†,å¹¶æä¾›ä¸€äº›æç¤ºä¿¡æ¯ã€‚
#SYSTEM æ ¹æ®è¾“å‡ºçš„ç½‘ç»œå°è¯´äººç‰©å¡ç‰‡,ç”Ÿæˆç¬¦åˆå°è¯´æƒ…èŠ‚çš„å¤§çº²,åŒ…å«ä¸»è¦äººç‰©çš„æ•…äº‹çº¿,ä¸»è¦äº‹ä»¶,æ³¨æ„è¦ç¬¦åˆç»™å®šè§’è‰²çš„æ€§æ ¼,å¤–è²Œå’Œç»å†ã€‚
#SYSTEM æ ¹æ®è¾“å…¥çš„å°è¯´å¤§çº²å’Œä¸Šä¸€ç« å†…å®¹,ç”Ÿæˆä¸‹ä¸€ç« ç»†çº²,å¹¶å†™å‡ºä¸‹ä¸€ç« çš„æ ‡é¢˜,ä¸»é¢˜,æƒ…èŠ‚èµ°å‘,çˆ½ç‚¹,ä¼ç¬”ã€‚æ¯å¼ å­—æ•°åœ¨1500-3000å­—ä¹‹é—´,è¦é¢„ç•™å‡ºä¸€äº›å­—æ•°ç»™ç»†èŠ‚æå†™ã€‚
#SYSTEM æ ¹æ®è¾“å…¥çš„ç« èŠ‚ç»†çº²,å†™å‡ºä¸‹ä¸€ç« ,å­—æ•°åœ¨1500-3000å­—ä¹‹é—´,å¹¶ä¿æŒæƒ…èŠ‚çš„è¿è´¯æ€§å’Œé€»è¾‘æ€§ã€‚åŒæ—¶ï¼Œè¯·é€‚å½“åœ¨å°è¯´ä¸­æå†™ç¯å¢ƒã€äººç‰©è¡¨æƒ…å’ŒåŠ¨ä½œï¼Œä»¥å¢åŠ æ•…äº‹çš„ç”ŸåŠ¨æ€§å’Œå¸å¼•åŠ›ï¼Œè®©è¯»è€…æ›´å®¹æ˜“æ²‰æµ¸å…¶ä¸­ã€‚

SYSTEM ä½ æ˜¯ä¸€ä¸ªæ°å‡ºçš„ä½œå®¶,èƒ½çµæ´»åœ°æ ¹æ®è¾“å…¥çš„è¯·æ±‚,è¾“å‡ºç¬¦åˆå°è¯´æƒ…èŠ‚çš„å¤§çº²,äººç‰©å¡ç‰‡,ç« èŠ‚ç»†çº²,ç« èŠ‚å†…å®¹ã€‚


TEMPLATE """{{ if .System }}<|im_start|>system
{{ .System }}<|im_end|>
{{ end }}{{ if .Prompt }}<|im_start|>user
{{ .Prompt }}<|im_end|>
{{ end }}<|im_start|>assistant
"""

```
## å°è¯• æ·»åŠ ç¤ºä¾‹
åœ¨å¯¹è¯ä¸­æ’å…¥ç¤ºä¾‹ã€‚
ä»templateä¸­è¯»å–å¯¹åº”æ–‡ä»¶å¤¹ï¼Œå¹¶è¯»å–txtæ–‡ä»¶,è·å¾—ç¤ºä¾‹ã€‚
ç›®å‰åªåœ¨éƒ¨åˆ†éœ€è¦aiè¿”å›jsonçš„åœ°æ–¹å®ç°,å› ä¸ºæ€»æ˜¯è¿”å›è¯»å–ä¸æˆåŠŸçš„ä¿¡æ¯ã€‚
>æ€»åœ¨å‰é¢åŠ ä¸Š```json
>ä¸å¤Ÿè§„èŒƒï¼Œå¯¼è‡´è¯†åˆ«åˆ°è¿‡å¤šåœºæ™¯ï¼Œåˆè€—æ—¶æ•ˆæœåˆä¸å¥½
 
> åŸé¡¹ç›®å¤„ç†æ–¹å¼ï¼šå¯¹aiè¿”å›çš„ä¿¡æ¯åˆ å»"``"å’Œ"json"
> æˆ–è®¸è¿˜å¯ä»¥åªå–ç¬¬ä¸€ä¸ª"["å’Œæœ€åä¸€ä¸ª"]"ä¹‹é—´çš„å†…å®¹
 
 
# todo
é‡è¿ç²’åº¦ä¸å¤Ÿç»†ã€‚4æ¸…æ´—ç« èŠ‚è¿™ä¸€æ­¥ä¹Ÿç›¸å½“è€—æ—¶
æ¨¡å‹å‚æ•°ä¸å¤Ÿå¤§ï¼Œå‡ºæ¥çš„æ•ˆæœæ²¡æœ‰åŸé¡¹ç›®çš„å¥½ã€‚å¯èƒ½éœ€è¦åœ¨è¾“å…¥çš„ä¿¡æ¯é‡ŒåŠ ä¸Šç¤ºä¾‹(done)ã€‚



# AI Story Generator ğŸ“šâœ¨

Generate full-length novels with AI! Harness the power of large language models to create engaging stories based on your prompts.

[![Discord](https://img.shields.io/discord/1255847829763784754?color=7289DA&label=Discord&logo=discord&logoColor=white)](https://discord.gg/R2SySWDr2s)

## ğŸš€ Features

- Generate medium to full-length novels: Produce substantial stories with coherent narratives, suitable for novella or novel-length works.
- Easy setup and use: Get started quickly with minimal configuration required.
- Customizable prompts and models: Choose from existing prompts or create your own, and select from various language models.
- Automatic model downloading: The system can automatically download required models via Ollama if they aren't already available.
- Support for local models via Ollama: Run language models locally for full control and privacy.
- Cloud provider support (currently Google): Access high-performance computing resources for those without powerful GPUs.
- Flexible configuration options: Fine-tune the generation process through easily modifiable settings.
- Works across all operating systems
- Supoorts translation of the generated stories in all languages

## ğŸ Quick Start

Getting started with AI Story Generator is easy:

1. Clone the repository
2. Install [Ollama](https://ollama.com/) for local model support
3. Run the generator:

```sh
./Write.py -Prompt Prompts/YourChosenPrompt.txt
```

That's it! The system will automatically download any required models and start generating your story.

**Optional steps:**

- Modify prompts in `Writer/Prompts.py` or create your own
- Configure the model selection in `Writer/Config.py`

## ğŸ’» Hardware Recommendations

Not sure which models to use with your GPU? Check out our [Model Recommendations](Docs/Models.md) page for suggestions based on different GPU capabilities. We provide a quick reference table to help you choose the right models for your hardware, ensuring optimal performance and quality for your story generation projects.

## ğŸ› ï¸ Usage

You can customize the models used for different parts of the story generation process in two ways:

### 1. Using Command-Line Arguments (Recommended)

You can override the default models by specifying them as command-line arguments:

```sh
./Write.py -Prompt Prompts/YourChosenPrompt.txt -InitialOutlineModel "ollama://llama3:70b" ...
```

Available command-line arguments are stated in the `Write.py` file.

The model format is: `{ModelProvider}://{ModelName}@{ModelHost}?parameter=value`

- Default host is `127.0.0.1:11434` (currently only affects ollama)
- Default ModelProvider is `ollama`
- Supported providers: `ollama`, `google`, `openrouter`
- For `ollama` we support the passing of parameters (e.g. `temperature`) on a per model basis

Example:
```sh
./Write.py -Prompt Prompts/YourChosenPrompt.txt -InitialOutlineModel "google://gemini-1.5-pro" -ChapterOutlineModel "ollama://llama3:70b@192.168.1.100:11434" ...
```

This flexibility allows you to experiment with different models for various parts of the story generation process, helping you find the optimal combination for your needs.


NOTE: If you're using a provider that needs an API key, please copy `.env.example` to `.env` and paste in your API keys there.


### 2. Using Writer/Config.py


Edit the `Writer/Config.py` file to change the default models:

```python
INITIAL_OUTLINE_WRITER_MODEL = "ollama://llama3:70b"
CHAPTER_OUTLINE_WRITER_MODEL = "ollama://gemma2:27b"
CHAPTER_WRITER_MODEL = "google://gemini-1.5-flash"
...
```

## ğŸ§° Architecture Overview

![Block Diagram](Docs/BlockDiagram.drawio.svg)

## ğŸ› ï¸ Customization

- Experiment with different local models via Ollama: Try out various language models to find the best fit for your storytelling needs.
- Test various model combinations for different story components: Mix and match models for outline generation, chapter writing, and revisions to optimize output quality.

## ğŸ’ª What's Working Well

- Generating decent-length stories: The system consistently produces narratives of substantial length, suitable for novella or novel-length works.
- Character consistency: AI models maintain coherent character traits and development throughout the generated stories.
- Interesting story outlines: The initial outline generation creates compelling story structures that serve as strong foundations for the full narratives.

## ğŸ”§ Areas for Improvement

- Reducing repetitive phrases: We're working on enhancing the language variety to create more natural-sounding prose.
- Improving chapter flow and connections: Efforts are ongoing to create smoother transitions between chapters and maintain narrative cohesion.
- Addressing pacing issues: Refinements are being made to ensure proper story pacing and focus on crucial plot points.
- Optimizing generation speed: We're continuously working on improving performance to reduce generation times without sacrificing quality.

## ğŸ¤ Contributing

We're excited to hear from you! Your feedback and contributions are crucial to improving the AI Story Generator. Here's how you can get involved:

1. ğŸ› **Open Issues**: Encountered a bug or have a feature request? [Open an issue](https://github.com/datacrystals/AIStoryWriter/issues) and let us know!

2. ğŸ’¡ **Start Discussions**: Have ideas or want to brainstorm? [Start a discussion](https://github.com/datacrystals/AIStoryWriter/discussions) in our GitHub Discussions forum.

3. ğŸ”¬ **Experiment and Share**: Try different model combinations and share your results. Your experiments can help improve the system for everyone!

4. ğŸ–Šï¸ **Submit Pull Requests**: Ready to contribute code? We welcome pull requests for improvements and new features.

5. ğŸ’¬ **Join our Discord**: For real-time chat, support, and community engagement, [join our Discord server](https://discord.gg/R2SySWDr2s).

Don't hesitate to reach out â€“ your input is valuable, and we're here to help!

## ğŸ“„ License

This project is licensed under the GNU Affero General Public License v3.0 (AGPL-3.0). This means that if you modify the code and use it to provide a service over a network, you must make your modified source code available to the users of that service. For more details, see the [LICENSE](LICENSE) file in the repository or visit [https://www.gnu.org/licenses/agpl-3.0.en.html](https://www.gnu.org/licenses/agpl-3.0.en.html).

---

Join us in shaping the future of AI-assisted storytelling! ğŸ–‹ï¸ğŸ¤–
